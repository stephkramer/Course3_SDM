---
title: "Course Species Distribution Modelling (SDM)"
date: "`r Sys.Date()`"
author: Stephanie Kramer-Schadt
output:
  rmdformats::readthedown:
    code_folding: show
    self_contained: true
    thumbnails: false
    lightbox: false
pkgdown:
  as_is: true    
editor_options: 
  chunk_output_type: console
---
<head>
<style>

h1 {color: Indigo; 
      background-color: white;
      text-align: left;
      <img src="C:/Users/kramer/PopDynIZW Dropbox/Steph Kramer/_GitHub/Course_SDM/D6_Logo.png" alt="d6 logo">

}
h2 {color: Indigo;} 
p {color: Grey;}

</style>
</head>


# Header 1

start to write text here

title: "Tutorial Part III - SDM preparations"
# author: Stephanie Kramer-Schadt, 
#         with Juergen Niedballa, Moritz Wenzler, Pierre Gras

## Header 2

``` bash
.
├── .gitignore
├── .Rbuildignore
├── data-raw
│   └── csv file with field data
├── output
│   └── csv file with results
├── plots
├── R
│   └── 01_khulan.Rmd with analysis code and knitted html
├── Rproj filename
└── README.Rmd etc
```





```{r, results="asis", echo=FALSE, message=FALSE, warning=FALSE}
#res <- knitr::knit_child('_example_body.Rmd', quiet = TRUE)
#cat(res, sep = '\n')
```

# Preparations
## Load libraries

```{r}

### The packages (repetition) ###
   library(here)
   library(sp)
   library(sf)
   library(tmap)
   library(dismo)
   library(raster)
   library(GISTools)
   library(rgdal)
   library(maptools)
   library(viridis)
   library(rgeos)
   library(rgl)
 # library(rasterVis) 
   library(unmarked)
   library(spatstat)

## check that the package terra is detached!
# detach(package:terra)
```

## Set the workspace

```{r}
### The workspace  (repetition) ###
getwd() # you can also use the package 'here()'

# my data are outside my course-folder, therefore I have to do it the old-fashioned way.
root_wd <- "E:/PopDynIZW Dropbox/Steph Kramer/_GitHub"
# relative to work-wd
maps_wd <- paste(root_wd,"/","_DataBorneo/BaseMaps",sep='')
recs_wd <- paste(root_wd,"/","_DataBorneo/BaseRecords",sep='')

# the output folder should have been created by you during Tutorial 2 'R goes spatial'.
# It should contain the hillshade.asc
output_wd <- paste(root_wd,"/","output",sep='')

setwd(output_wd) ## set to the OUTPUT folder!
getwd()
```

## Load spatial data and define the CRS

### Load rasters

```{r}
### Data import - Load spatial data (repetition) ###
## note, here I use the 'dialect' of the old 'raster'-package.

ras1 <- raster(paste(maps_wd,'/bio_asc_01.asc',sep=''))
# assign the projection (crs - coordinate reference system)
ras1@crs <- CRS("+proj=longlat +datum=WGS84")

ras24 <- raster(paste(maps_wd,'/bio_asc_24.asc',sep='')) #DEM
ras24@crs <- ras1@crs # same as: CRS("+proj=longlat +datum=WGS84")

ras42 <- raster(x = paste(maps_wd,'/bio_asc_42.asc',sep='')) 
ras42@crs <- CRS(projargs = "+init=epsg:4326") 

hillsh <- raster(x = paste(output_wd,'/hillshade.asc',sep='')) 
hillsh@crs <- CRS(projargs = "+init=epsg:4326")
```

### Stack environmental variables

Loading many rasters can be done in one go.
```{r}
### Raster stack of environmental predictors (repetition) ###

# the list.files command is very helpful to check what is in the folders
# use 'pattern' for searching for special file types, here .asc-files:
files <- list.files(path= maps_wd, pattern='.asc$',
                    full.names=TRUE )
files # these are just names! To load them as spatial objects, use raster() or stack()
predictors <- stack(files[c(9,12,22,24)]) # note that I only load 4 rasters

# set CRS:
predictors@crs <- CRS(projargs = "+init=epsg:4326")
```

### Plot rasters
```{r}
plot(predictors, col= viridis(100)) # might take some time depending on your computer

# what are the differences? Have a look also at the data description file in the data folder.
```

### Load shapefiles

```{r}
### Read in some Shapefiles (repetition) ###

# package sp (old, but easier for plotting)
Borneo_shp <- readOGR(dsn=maps_wd, layer="borneo_admin",
              stringsAsFactors=FALSE)[,c(1:3,5,7,17,18)] #only load some of the coulmns of df
PA_shp <-  readOGR(dsn=maps_wd, layer="Bor_PA",
                   stringsAsFactors=FALSE)[,c(1:4)]
River_shp <- readOGR(dsn=maps_wd, layer="sn_100000",
                     stringsAsFactors=FALSE)

# package sf (new and maintained)
# Borneo outline polygon
Borneo_shp_sf <- st_read(dsn = maps_wd, 
                      layer = "borneo_admin",
                      stringsAsFactors = FALSE)[,c(1:3,5,7,17,18)]
# Protected areas (PA) polygon
PA_shp_sf <-  st_read(dsn = maps_wd, 
                   layer = "Bor_PA",
                   stringsAsFactors = FALSE)[, c(1:4)]
# Rivers lines
River_shp_sf <- st_read(dsn = maps_wd, 
                     layer = "sn_100000",
                     stringsAsFactors = FALSE)
```

### Load point df and convert to spatial object


These are our observations of the species.
```{r}
### The spatial point data (species records) (repetition) ###

# filename
spec_pt_filename <- paste(recs_wd,'/','MyNewSpecies.csv', sep='')
spec_pt_filename

# you can play also with other files
#spec_pt_filename <- paste(recs_wd,'/','DHOsim.csv',sep='')
#spec_pt_filename <- paste(recs_wd,'/','PPLsim.csv',sep='')

# read the file
sp_recs <- read.csv(file = spec_pt_filename, header=TRUE, sep=',')

#convert it to spatial object (sf here)
sp_recs_sf <- st_as_sf(x = sp_recs, 
                       coords = c("long","lat"), # columns  for the coordinates
                       crs = 4326, # define crs, 4326 is the EPSG code
                       sf_column_name = "geometry",
                       remove=F) # sf needs a geometry column and you have to name it

# load a second species 
river_pt_filename <- paste(recs_wd,'/','RIVERsim.csv',sep='')
river_recs        <- read.csv(file = river_pt_filename, header=TRUE, sep=',')
river_recs_sf     <- st_as_sf(x = river_recs,
                          coords = c("long", "lat"), 
                          crs = 4326, 
                          sf_column_name = "geometry")
```

## Plot

```{r}
### Plot to get an impression ###

plot(ras42, col=grey.colors(20))
plot(PA_shp,border='green', lwd=1.8, add=T)
plot(sp_recs_sf$geometry, pch= '*',cex=1,col='deeppink',add=T)
text(112, 5, 'Starting with SDMs', cex=2, col= 'red')
plot(River_shp[,3], col='dodgerblue4', add=T)
```

# Preconditions 

## Checking for multicollinearity

```{r}
# workaround for slow computers. First, aggregate the 1 km² resolution into 50*50 km  
agg_pred <- aggregate(x=predictors,fact=50,FUN=mean)
plot(agg_pred)
```

### Pairs plot 

```{r}
raster::pairs(agg_pred, method = 'spearman')
```


```{r}
# Plot the differences (residuals) between the rasters:
diff <- raster::corLocal(x = agg_pred[[1]], y = agg_pred[[2]], method = 'spearman')
plot(diff)
```


```{r}
# not_run on slow computers:
#pairs(predictors)
```

NB: I am a big fan of the pairs()-plot because you actually see the distribution of the data, but you can do really nice plots with the `{corrplot}`-package: <br>
https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html

## Sampling bias correction


We are now creating a very rudimentary bias correction file. Let's assume that doing field work in the province of Sabah, Malaysia, is easy and the field sampling has concentrated on these areas. further, it is easier to sample in lowlands and flat slopes. Usually, protected areas (PAs) are also well studied areas, where the sampling intensity is high. And let's assume that it was not possible to get a research permit for Indonesia and that therefore very few field studies had been conducted here. Please note: this is a completely fictive example! You should have the information about the sampling bias.

That is, we create a file that is representing these differences in sampling effort. this is easiest to do in raster manipulation. We first create a raster from our shapefile with the country outlines. 

```{r}
head(Borneo_shp_sf)
plot(Borneo_shp_sf[,3]) # column 3 is NAME_0
```

We create a raster that gets the value of 1 for Malaysia (and Brunei) and a value of 0.01 (MaxEnt cannot deal with 0 -> see lecture) for the rest. We use one of our rasters as mask for cell size resolution and cropping extent:

```{r}
### *Rasterize* the shapefiles
## command rasterize() 
## field = 1 means all raster cells get value = 1, other cell values are set to 0
## background sets all other cells to a chosen number


Mal_ras <- rasterize(x=Borneo_shp_sf[Borneo_shp_sf$NAME_0 %in%
                       c("Brunei","Malaysia"),], y=ras24, field=1,
                       background=0.1)

plot(Mal_ras)

# almost same as:
# NotInd_ras <- rasterize(x=Borneo_shp_sf[Borneo_shp_sf$NAME_0 !=
#                           "Indonesia",], y=ras24, field=1, background=0.01)
```

We do the same only for the province of Sabah and the Protected Areas

```{r}
Sab_ras <- rasterize(x=Borneo_shp_sf[Borneo_shp_sf$NAME_1 == 'Sabah',],
                     y=ras24, field=1, background=0.1)

PA_ras <- rasterize(x=PA_shp, y=ras24, field=1, background=0.1)


### Crosscheck with plot
par(mfrow=c(1,2))
plot(Sab_ras)
plot(PA_ras) #n.b.: only 1 and small values, no NA
par(mfrow=c(1,1))
```

And we do the same for all elevations below 300 m:
```{r}
ras24_300 <- ras24 <= 300
plot(ras24_300)
```

Now we add them all up. This means, we rank the sampling intensity, i.e. sampling in protected areas in Sabah below 300 m gets the highest value

```{r}
bias_tmp <- ras24_300 + Sab_ras + Mal_ras + PA_ras
bias_tmp
plot(bias_tmp)
```

Let's standardize between 0 and 1 (and then set the zeros to 0.01 again)
```{r}
# get the maximum value in the layer, standardize it and round to two decimals
maxval <- max(values(bias_tmp),na.rm=T)
bias_tmp2 <- bias_tmp/maxval
bias_tmp3 <- round(bias_tmp2, digits=2)

## same as in one go:   
bias1 <- round(bias_tmp/max(values(bias_tmp),na.rm=T),digits=2)

table(values(bias1)) 
# table(bias1@data@values) # is doing the same

### in case of having 0 somewhere:
bias1[values(bias1 == 0)] <- 0.01 # because MaxEnt
                                  # does not take 0!
table(values(bias1))
```


```{r}
### Compare rasters - Are they the same?

# The input rasters all have the same amount of cells, i.e. ras24
# (or any other of the maps in the predictors stack) can be used as a template/ mask.
compareRaster(ras24,bias1) # the same?

# Are they really the same???
length(which(!is.na(values(bias1))))
length(which(!is.na(values(ras24))))

# save into Output folder, which is your working directory: 
# check with getwd() if you're not sure of wd

#bias_agg <- aggregate(bias1, fact=75,FUN=mean)
#writeRaster(bias_agg, filename="bias_agg.asc", datatype='ascii',
#            overwrite=TRUE,NAflag=-9999)



writeRaster(bias1, filename="bias1.asc", datatype='ascii',
            overwrite=TRUE,NAflag=-9999)

# Please change the cell size in the header of the bias ascii 'by hand'
# before entering it into MaxEnt!!!**
# Sometimes there are long numbers!
# By hand means: please open the bias1.asc file in the Editor
# set CELLSIZE 0.0083333337997189 to 0.0083333338


### Plot the bias file
plot(bias1, col = grey.colors(7))

################  end ##########################################################
# either create the following folders in R or do it by hand in the explorer:
#dir.create(path = file.path(output_wd, "MaxEntRes"), showWarnings = FALSE)
#dir.create(path = file.path(output_wd, "/MaxEntRes", "nobias"),showWarnings = FALSE)
#dir.create(path = file.path(output_wd, "/MaxEntRes", "withbias"),showWarnings = FALSE)


#### if MaxEnt is not working with bias file, 
# exchange full ascii header with copy-paste


#### meanwhile clicking Maxent.... 
# (or: do it with R package dismo, but this is another story
#  which will be taught another time....)


################################################################################
### Accessing MaxEnt results
################################################################################

# Have a look at the MaxEnt layers produced
# MaxEnt saves the mean of x repetitions in _avg.asc

# only works with the folder structure
# MaxEntRes/nobias
# MaxEntres/withbias

# new argument 'recursive' means, that also subf?lders are checked!
infiles <- list.files(path=paste(output_wd,'/MaxEntRes',
                                 sep=''),pattern='_avg.asc$',
                      full.names=TRUE,recursive=TRUE )
infiles

# example
#[1] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /nobias/river_dummy_avg.asc"
#[2] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /nobias/river_dummy_FutureMaps_avg.asc"
#[3] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /withbias/river_dummy_avg.asc"
#[4] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /withbias/river_dummy_FutureMaps_avg.asc"


### Stack results file and make usual plot

# IF you have a slow computer, 
# please use the workaround with function aggregate() from above

me_stack <- aggregate(stack(infiles[c(1:4)]),fact= 50, FUN = mean )

me_stack <- stack(infiles[c(1:4)])


# name sequence according to infiles list above
names(me_stack) <- c('curr_noBias','fut_noBias',
                     'curr_withBias','fut_withBias')

#par(mar=c(4,4,3,3), oma=c(2,2,2,2))

plot(me_stack,col=viridis(100)) # note: I might use a different example

### Make violin plot
# Rearrange order to better compare impact of bias file
# i.e. plot present climate maps next to each other, and the future ones
#bwplot(me_stack)
bwplot(me_stack,layers = c(1,3,2,4)) #rearrange

# alternative
boxplot(me_stack,layers = c(1,3,2,4),notch=T,outline=F)


################################################################################
### Threshold selection
################################################################################

# Use maxentResults.csv to access threshold value
# column: 10th percentile training presence logistic threshold

me_res <- list.files(path=paste(output_wd,'/MaxEntRes',sep=''),
                     pattern='maxentResults.csv',
                     full.names=TRUE,recursive=TRUE )
me_res

# example
#[1] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /nobias/maxentResults.csv"
#[2] "c:/Users/kramer/Dropbox/.../MaxEntRes
#     /withbias/maxentResults.csv"
store_res <- lapply(me_res,FUN=read.csv) #store as list obj.
head(store_res) # list object with 2 slots
str(store_res)
store_res[[1]]

# Extract the values at column '10th percentile' at position nrep +1
# (= nrow command) to access avg value of all repetitions

zename<-'X10.percentile.training.presence.logistic.threshold' # check if the column name is the same !!!!!
# Achtung! 
# In MaxEnt 3.4.1 heisst Spalte 'X10.percentile.training.presence.Logistic.threshold'
zecol <-which(colnames(store_res[[1]]) == zename) 
zecol

# a little head twister:
# access each element of your list, which is a whole dataset with store_res[[1]]
# and inside this list object = data.frame, access the element of
# the 8last row (nrow), and the column zecol] containing the threshold value
t_noBias   <- store_res[[1]][nrow(store_res[[1]]),zecol]
t_withBias <- store_res[[2]][nrow(store_res[[2]]),zecol]

t_noBias #the thresholds
t_withBias


# Apply thresholds to relative probability maps
# Plot the binary maps and compare different threshold outcomes
all_bias <- rep(c(t_noBias,t_withBias), each=2)
all_bias

#dev.off()
#plot(me_stack)

binary_thresh <- me_stack >= all_bias

test2 <- me_stack >= 0.5 # check result with fixed threshold
#test3 <- me_stack >= seq(0.1, 0.7, length = 4)

plot(binary_thresh)
plot(test2)
#plot(test3)


# Extract relative probability values inside protected areas PAs
# check if overlay correct - only works when you have NOT aggregated the maps
compareRaster(PA_ras,me_stack[[1]]) 

ex <- which(values(PA_ras)==1)
ex # gives Pointer to elements/ Index
ex_stack <- extract(x=me_stack, y=ex)
head(ex_stack)
#plot(ex_stack)

## Plot the difference of habitat suitability in scenarios and PAs
boxplot(ex_stack,na.rm=T)

### Calculate no. of cells (=area) of suitable habitat in PAs
ex_binary <- extract(x=binary_thresh, y=ex)
head(ex_binary)
ex_binary[1:2,]; colSums(ex_binary,na.rm=T) #2 cmnds in line with ; !

################# just in case for Netlogo   ###################################
### maps have to be smaller and instead of NA put -1 ###

infiles # remember, out folder content

# chose one:
my_MaxEnt_avg_Map <- raster(infiles[1])
my_MaxEnt_avg_Map@crs <- CRS("+proj=longlat +datum=WGS84")

# plot
plot(my_MaxEnt_avg_Map,col=viridis(100))

# save it with a lower resolution (similar to 'aggregate')
probab_agg <- aggregate(x=my_MaxEnt_avg_Map,fact=2,fun=mean)

#and make an integer out of the decimals
probab_agg_int <- as.integer(round(probab_agg*100, digits=0))
plot(probab_agg_int, col=viridis(100))

# save it to import into Netlogo
getwd() # that's where it is saved now
writeRaster(probab_agg, filename="probab_agg_int",format="ascii",
            overwrite=TRUE,NAflag = -9999)


################################################################################
### Tutorial Part III - least cost path [LCP] for connectivity
################################################################################
## Least cost path
### package for LCP
#install.packages('gdistance')

library(gdistance)
#?gdistance

# Set start and end points: centers of the first two PA polygons
start <- gCentroid(PA_shp[1,1], byid=FALSE, id = NULL)
end   <- gCentroid(PA_shp[2,1], byid=FALSE, id = NULL)

# Several commands in one line when separated by ';':
plot(me_stack[[1]]); points(start); points(end)

# Clip raster to save computation time
cr_extent <- c(114,117,3,6.5)
me_cr <- crop(x=me_stack[[1]],y=cr_extent)
plot(me_cr); points(start,pch=15); points(end,pch=15)

### Necessary calculations
# Calculate the transition layer
trans <- transition(x = me_cr,
                    transitionFunction = mean,
                    directions = 4,
                    symm = F)
class(trans)

# Calculate the shortest weighted connection
sPath <- shortestPath(trans, start, end,
                      output="SpatialLines")

crs(sPath) <- "+proj=longlat +datum=WGS84 +no_defs"


# Calculate the length of the path
costDistance(trans, start, end) #units?


# Make a plot
plot(me_cr,col=viridis(100)); points(start,pch=15); points(end,pch=15)
lines(sPath,lwd=1, col= 'red'); plot(PA_shp, border='white', lwd=0.5,add=T)


# where does the animal corridor intersect rivers?
# in sf package
River_inter1 <- st_intersection(x = River_shp_sf, y = as(sPath, "sf")) 
# in sp package
# River_inter_sp <- gIntersection(River_shp, sPath) 

plot(sPath,lwd=3); plot(PA_shp,border='grey',lwd=1,add=T)
plot(River_shp,col='blue',lwd=2,add=T)
plot(River_inter1,col='red',lwd=4,add=T); box()




######## currently out of order
# Which connections intersect the PAs?
PA_inter1 <- st_intersection(x = PA_shp_sf, y = as(sPath, "sf")) 

plot(sPath,lwd=3); plot(PA_shp,border='blue',lwd=2,add=T)
lines(PA_inter1,col='red',lwd=4); box()

### Save new line as shapefile
crs(sPath) <- CRS('+proj=longlat +datum=WGS84')
cp_line <- SpatialLinesDataFrame(sl=sPath,
                                 data = data.frame(name = c(1:length(sPath@lines))))
writeOGR(obj=cp_line,dsn=output_wd,layer='costpath_line',
         driver = 'ESRI Shapefile', overwrite = TRUE)
#### end currently out of order

################  end #######################



```



